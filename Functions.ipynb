{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VGG_imagnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutia2044/rutiarbiv-gmail.com/blob/master/Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEQPbjVPDhFP"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        " \n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        " \n",
        "import os\n",
        "import glob\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "from tensorflow import keras,summary\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wynBkqLqCSVZ"
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "def Load_images():\n",
        "  images = []\n",
        "  root = '/content/drive/MyDrive/gan-getting-started/monet_jpg'\n",
        "  for file in tqdm(os.listdir(root)):\n",
        "      images.append(plt.imread(root+'/'+file))\n",
        "  images = np.array(images)\n",
        "  return images"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO5r-Wh6pMLt"
      },
      "source": [
        "FID -calculating the frechet inception distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srRjE5repLk3"
      },
      "source": [
        "\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "#inputs:\n",
        "#act1,act2 =The features extractions of 2 groups of images\n",
        "#the features extractions done by trained model:InceptionV3/VGG..\n",
        "\n",
        "#output:\n",
        "#FID- calculated frechet inception distance\n",
        "\n",
        "def calculate_fid( act1, act2):\n",
        "\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRCHVu_v2ZOw"
      },
      "source": [
        "#rand 100 vectors of 30 indexs\n",
        "def Find_indexes_whith_min_Fid_from_random_vectors(act1, act2):\n",
        "  min=300\n",
        "  #max=0\n",
        "  AllImages = preprocess_input(images)\n",
        "  for number in range(100):   \n",
        "      rndArr=np.random.choice(300, 30)\n",
        "      selectImg=images[rndArr,:,:,:]\n",
        "      selectImg1 = preprocess_input(selectImg)\n",
        "      fid = calculate_fid( AllImages, selectImg1)\n",
        "      if fid < min:\n",
        "        print('FID (temp min): %.3f' % fid)\n",
        "        print(number)\n",
        "        min=fid\n",
        "        minIndx= rndArr\n",
        "  print('MIN Final---FID : %.3f' % min)\n",
        "  print(minIndx)\n",
        "  return min, minIndx\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuoyhN_8iCwv"
      },
      "source": [
        "CLUSTERING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIZlRWRGEJAQ"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import collections\n",
        "\n",
        "def Find_indexes_foreach_cluster(act1, act2):\n",
        "  kmeans = KMeans(n_clusters=30).fit(tsneAllImages)\n",
        "  collections.Counter(kmeans.labels_)\n",
        "  select=[]\n",
        "  for i in range (30):\n",
        "    select.append(np.nonzero(kmeans.labels_ == i)[0][0])\n",
        "  return select"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}